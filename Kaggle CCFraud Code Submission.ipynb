{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7bfad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Kaggle European Credit Card Dataset\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d249c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "############################################################################################\n",
    "Overview-\n",
    "\n",
    "In this project, I'm predicting  fraud using three ML models: Random Forest , XGBoost, and a Multi-layer\n",
    "Perceptron (MLP). I tried to use a consistent processing and eval pipeline to ensure that the comparisons\n",
    "between them are  fair. Also, to address the dataset's severe class imbalanc, which is typical in fraud\n",
    "datasets, two sampling techniques—SMOTE  & Random UnderSampling- are applied to improve minority class\n",
    "representation.\n",
    "\n",
    "Feature Engineering: Ihe \"Time\" feature is removed, because it lacks informational value. \n",
    "Additionally, features V22 to V28 are dropped due to low variance.  (Will be  detailed in final report).\n",
    "\n",
    "\n",
    "*NOTE on Dataset Downsampling:  \n",
    "Due to compute and time constraints associated with training some models on full dataset, a\n",
    "stratified sample of the data was used for some model configs. This allowed for faster training\n",
    "without compromising the class balance, ensuring the model still learns patterns from  both classes.\n",
    "I had to do this to avoid system overheating and runtime limitations (e.g., timeouts when I also tried with colab)\n",
    "while still providing a representative dataset for training and eval.\n",
    "\n",
    "\n",
    "Train-Test Split: A train-test split of 80-20 is performed with stratification. \n",
    "Stratification ensures that training and testing sets maintain the original dataset's class\n",
    "distribution, helping the model generalize well without bias toward one class.\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "Avoiding Data Leakage-\n",
    "Data leakage, where information from test set can influence the training set, is carefully avoided through\n",
    "the following measures:\n",
    "\n",
    "Proper Train-Test Split: The test data is kept separate from the training data before any transformations,\n",
    "sampling/scaling which ensures model evaluation is fair and representative of real-world performance.\n",
    "\n",
    "Pipeline use: The transformation and sampling process is wrapped up in a pipeline, meaning that data\n",
    "transformations (scaling, sampling) are applied only on the training data during cross-val and model training.\n",
    "This approach avoids access to information from test set that could bias the models.\n",
    "\n",
    "\n",
    "Model Pipeline:\n",
    "\n",
    "Pipeline Construction: A pipeline is created, which includes:\n",
    "Scaling: The StandardScaler scales features. \n",
    "\n",
    "Sampling Techniques: Two sampling methods are tested independently:\n",
    "-SMOTE: This technique synthesizes new instances for the minority class, balancing the class distribution.\n",
    "-Random Under-Sampling: This technique reduces majority class by randomly sampling it down to a size thts\n",
    "closer to the minority class.\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "Parameter Tuning: \n",
    "-GridSearchCV is used to optimize model hyperparameters by systematically testing different combinations\n",
    "of params and evaluating each combinations performance. This process is important because hyperparameters\n",
    "(e.g., the number of trees in a Random Forest or the max depth of trees) can significantly impact a model.\n",
    "-After evaluating all combos, GridSearchCV selects the one with the highest score for the selected metric (ROC AUC).\n",
    "This best model is then re-trained on the entire training set using this  configuration, making it ready for the\n",
    "final test sett.\n",
    "-Using the stored metrics in cv_results_  we can extract metrics from GridSearchCV run,allowing\n",
    "analysis of model performance across various metrics and parameters.\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "Cross-Val: Cross-validation with roc_auc as the primary metric is applied to ensure the model’s reliability.\n",
    "By using 3-fold cross-validation, we measure performance across different folds, which gives a more robust\n",
    "indication of the model's effectiveness.\n",
    "\n",
    "With imbalanced classification tasks, it’s usually useful to use Stratified K-Fold CV  Stratified\n",
    "K-Fold ensures each fold maintains same class proportion as the entire dataset, which is useful\n",
    "when dealing with rare events like fraud. This ensured each fold has a similar balance between\n",
    "fraud and non-fraud, leading to more consistent training and evaluation across folds.\n",
    "\n",
    "Evaluation: Each model configuration is evaluated with: metrics like precision, recall, and F1-score\n",
    "to assess model performance. ROC AUC Score (Area Under the Receiver Operating Characteristic curve),\n",
    "is used because it is well-suited for imbalanced datasets and measures the model’s ability to distinguish\n",
    "between classes.\n",
    "\n",
    "Training and Inference Time: The average times for training and inference are recorded to understand\n",
    "the computational efficiency of each sampling approach.\n",
    "\n",
    "Satability: Shows the SD of roc_auc across folds, giving insight into model stability.\n",
    "\n",
    "Final Test Set Performance: The final model from GridSearchCV is evaluated on the test set for metrics\n",
    "such as precision, recall, F1-score, and ROC AUC to confirm its effectiveness on unseen data.\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "******** NOTE on RandomUndersampler: ********\n",
    "\n",
    "Across all models, the use of RandomUnderSampler consistently resulted in unusaable performance. This\n",
    "is because of significant loss of information from the majority class during undersampling, which reduced\n",
    "dataset size and limited the model's ability to learn. Initial dataset size reduction in some\n",
    "cases also contributed to this.  This was a big lesson learned.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea12a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RANDOM FOREST ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca020cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with smote...\n",
      "Best parameters for smote: {'classifier__max_depth': 10, 'classifier__n_estimators': 100}\n",
      "Cross-Validation ROC AUC Mean for smote: 0.974\n",
      "Cross-Validation ROC AUC Std Dev for smote: 0.013\n",
      "Confusion Matrix for smote:\n",
      "[[28405    27]\n",
      " [    7    42]]\n",
      "Test Set Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.61      0.86      0.71        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.80      0.93      0.86     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "Test Set ROC AUC for smote: 0.983\n",
      "Average Training Time for smote: 40.664 seconds\n",
      "Average Inference Time for smote: 0.315 seconds\n",
      "\n",
      "Evaluating model with undersample...\n",
      "Best parameters for undersample: {'classifier__max_depth': 10, 'classifier__n_estimators': 100}\n",
      "Cross-Validation ROC AUC Mean for undersample: 0.971\n",
      "Cross-Validation ROC AUC Std Dev for undersample: 0.021\n",
      "Confusion Matrix for undersample:\n",
      "[[27649   783]\n",
      " [    4    45]]\n",
      "Test Set Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     28432\n",
      "           1       0.05      0.92      0.10        49\n",
      "\n",
      "    accuracy                           0.97     28481\n",
      "   macro avg       0.53      0.95      0.54     28481\n",
      "weighted avg       1.00      0.97      0.98     28481\n",
      "\n",
      "Test Set ROC AUC for undersample: 0.991\n",
      "Average Training Time for undersample: 0.164 seconds\n",
      "Average Inference Time for undersample: 0.265 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\ssain\\Downloads\\CCfraud\\creditcard.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 'Time' removed - no informational value\n",
    "df = df.drop(columns=['Time'])\n",
    "df = df.drop(columns=[f'V{i}' for i in range(22, 29)])  # dropped (low variance)\n",
    "\n",
    "# Downsample dataset for faster processing\n",
    "# Group by 'Class' (fraud or not) and take a 50% sample from each group\n",
    "df_sampled = df.groupby('Class', group_keys=False).apply(lambda x: x.sample(frac=0.5, random_state=42))\n",
    "\n",
    "# # Split data into features and target\n",
    "X = df_sampled.drop(['Class'], axis=1)\n",
    "y = df_sampled['Class']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Define parameter grid and scorers\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [50, 100], # number of trees\n",
    "    'classifier__max_depth': [10],  # Max depth\n",
    "}\n",
    "\n",
    "# eval metrics for GridsearchCV\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "\n",
    "# Function to Evaluate models with both samplers\n",
    "def evaluate_model_with_sampler(sampler, sampler_name):\n",
    "    print(f\"Evaluating model with {sampler_name}...\")\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        (sampler_name, sampler),\n",
    "        ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Stratified K-Folds ensures balanced class dist.\n",
    "    strat_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Perform hyperparam tuning, refit based on ROCAUC \n",
    "    grid_search = GridSearchCV(pipeline, param_grid_rf, cv=strat_cv, scoring=scoring, refit='roc_auc', return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Display best parameters and cross-validation results\n",
    "    print(f\"Best parameters for {sampler_name}: {grid_search.best_params_}\")\n",
    "    cv_results = grid_search.cv_results_\n",
    "    best_index = grid_search.best_index_\n",
    "    roc_auc_mean = cv_results['mean_test_roc_auc'][best_index]\n",
    "    roc_auc_std = cv_results['std_test_roc_auc'][best_index]\n",
    "    print(f\"Cross-Validation ROC AUC Mean for {sampler_name}: {roc_auc_mean:.3f}\")\n",
    "    print(f\"Cross-Validation ROC AUC Std Dev for {sampler_name}: {roc_auc_std:.3f}\")\n",
    "    \n",
    "    # Extract training and inference times\n",
    "    train_time = cv_results['mean_fit_time'][best_index]\n",
    "    inference_time = cv_results['mean_score_time'][best_index]\n",
    "\n",
    "    # Evaluate on test set\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for {sampler_name}:\")\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"Test Set Metrics:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Test Set ROC AUC for {sampler_name}: {roc_auc_score(y_test, y_proba):.3f}\")\n",
    "    print(f\"Average Training Time for {sampler_name}: {train_time:.3f} seconds\")\n",
    "    print(f\"Average Inference Time for {sampler_name}: {inference_time:.3f} seconds\\n\")\n",
    "\n",
    "# Evaluate with SMOTE\n",
    "evaluate_model_with_sampler(SMOTE(random_state=42), 'smote')\n",
    "\n",
    "# Evaluate with RandomUnderSampler\n",
    "evaluate_model_with_sampler(RandomUnderSampler(random_state=42), 'undersample')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c2dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910fa15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### XG BOOST ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf984b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "367b9925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resampling Method: SMOTE\n",
      "Confusion Matrix for SMOTE:\n",
      "[[28420    12]\n",
      " [    9    40]]\n",
      "Test Set Metrics with Default Threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.77      0.82      0.79        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.88      0.91      0.90     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "Test Set ROC AUC: 0.977\n",
      "Best Parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 6, 'classifier__n_estimators': 200, 'classifier__scale_pos_weight': 1}\n",
      "Mean Train Time (s): 2.0349721908569336\n",
      "Mean Inference Time (s): 0.09009852409362792\n",
      "CV ROC AUC Mean: 0.7538088547189821\n",
      "CV ROC AUC Std Dev: 0.019381475787937003\n",
      "\n",
      "Resampling Method: RandomUnderSampler\n",
      "Confusion Matrix for RandomUnderSampler:\n",
      "[[27425  1007]\n",
      " [    4    45]]\n",
      "Test Set Metrics with Default Threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     28432\n",
      "           1       0.04      0.92      0.08        49\n",
      "\n",
      "    accuracy                           0.96     28481\n",
      "   macro avg       0.52      0.94      0.53     28481\n",
      "weighted avg       1.00      0.96      0.98     28481\n",
      "\n",
      "Test Set ROC AUC: 0.989\n",
      "Best Parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 6, 'classifier__n_estimators': 100, 'classifier__scale_pos_weight': 1}\n",
      "Mean Train Time (s): 0.14488277435302735\n",
      "Mean Inference Time (s): 0.07304801940917968\n",
      "CV ROC AUC Mean: 0.04085689634703589\n",
      "CV ROC AUC Std Dev: 0.025846762067911373\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\ssain\\Downloads\\CCfraud\\creditcard.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'Time' column and keep PCA features (need them in this case)\n",
    "df = df.drop(columns=['Time'])\n",
    "\n",
    "# Downsample the dataset for quicker training\n",
    "# Sample 50% of the data from each class to maintain balance\n",
    "df_sampled = df.groupby('Class', group_keys=False).apply(lambda x: x.sample(frac=0.5, random_state=42))\n",
    "\n",
    "# Split data into features and target using the sampled data\n",
    "X = df_sampled.drop(['Class'], axis=1)\n",
    "y = df_sampled['Class']\n",
    "\n",
    "# Split into training and test sets with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Define resamplers\n",
    "resamplers = {\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'RandomUnderSampler': RandomUnderSampler(random_state=42)\n",
    "}\n",
    "\n",
    "# Define model and parameter grid\n",
    "param_grid_xgb = {\n",
    "    'classifier__n_estimators': [100, 200], # boosting rounds\n",
    "    'classifier__max_depth': [4, 6],        # tree depth\n",
    "    'classifier__learning_rate': [0.01, 0.1],\n",
    "     #scaling for class imbalance\n",
    "    'classifier__scale_pos_weight': [1, len(y_train[y_train == 0]) / len(y_train[y_train == 1])]\n",
    "}\n",
    "\n",
    "# Set up scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "\n",
    " # Use Stratified K-Folds for Cross-Validation\n",
    "strat_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop through resamplers\n",
    "for name, resampler in resamplers.items():\n",
    "    print(f\"\\nResampling Method: {name}\")\n",
    "    \n",
    "    # Define pipeline  !!!!!!\n",
    "    pipeline_xgb = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('resampler', resampler),\n",
    "        ('classifier', XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='aucpr',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Perform GridSearchCV to find the best hyperparameters\n",
    "    #  refit on precision (gave better performance than ROCAUC etc.)\n",
    "    grid_search_xgb = GridSearchCV(pipeline_xgb, param_grid_xgb, cv=strat_cv, scoring=scoring, refit='precision')\n",
    "    grid_search_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the best model on the test set !!\n",
    "    best_model_xgb = grid_search_xgb.best_estimator_\n",
    "    y_pred = best_model_xgb.predict(X_test)\n",
    "    y_pred_proba = best_model_xgb.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for {name}:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Print classification report and ROC AUC for the test set\n",
    "    print(\"Test Set Metrics with Default Threshold:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Test Set ROC AUC: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
    "    \n",
    "    # Extract best model index and retrieve its metrics\n",
    "    best_index = grid_search_xgb.best_index_\n",
    "    train_time_best = grid_search_xgb.cv_results_['mean_fit_time'][best_index]\n",
    "    inference_time_best = grid_search_xgb.cv_results_['mean_score_time'][best_index]\n",
    "    cv_roc_auc_mean = grid_search_xgb.best_score_\n",
    "    cv_roc_auc_std = grid_search_xgb.cv_results_['std_test_roc_auc'][best_index]\n",
    "    \n",
    "    # Display metrics for the best model\n",
    "    print(f\"Best Parameters: {grid_search_xgb.best_params_}\")\n",
    "    print(f\"Mean Train Time (s): {train_time_best}\")\n",
    "    print(f\"Mean Inference Time (s): {inference_time_best}\")\n",
    "    print(f\"CV ROC AUC Mean: {cv_roc_auc_mean}\")\n",
    "    print(f\"CV ROC AUC Std Dev: {cv_roc_auc_std}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomUndersampler giving extremely low precision\n",
    "# When undersampling, we're drastically reducing the number of non-fraudulent\n",
    "# samples to match the minority (fraudulent) class, which is likely causing \n",
    "# severe information loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### MLP ############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94cb7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "##  MLP ########################################\n",
    "\n",
    "# This Multi-Layer Perceptron (MLP) is a feedforward neural net designed for binary classification.\n",
    "# In this implementation, the Multi-Layer Perceptron (MLP) consists of an input layer, two hidden layers with\n",
    "# ReLU activation, and an output layer with a sigmoid activation function for binary classif. The hidden\n",
    "# layers are designed with a moderate number of neurons to balance complexity and computational efficiency, while\n",
    "# dropout layers are added to prevent overfitting. This design was chosen to capture relationships\n",
    "# in the data while remaining computationally practical given resource constraints.\n",
    "\n",
    "\n",
    "# Note:create_model is a factory function used by KerasClassifier to generate new model instances dynamically.\n",
    "# Although we only define create_model once, it’s called multiple times by KerasClassifier during training,\n",
    "# cross-validation, and hyperparameter search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b335c2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Results with SMOTE...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      "Results with SMOTE:\n",
      "Best Parameters: {'mlp__model__optimizer': 'adam', 'mlp__model__neurons': 64, 'mlp__model__dropout_rate': 0.3, 'mlp__epochs': 50, 'mlp__batch_size': 128}\n",
      "Test Accuracy: 0.9991924440855307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28424\n",
      "           1       0.81      0.77      0.79        57\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.91      0.89      0.90     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "ROC-AUC Score: 0.9486\n",
      "Confusion Matrix for SMOTE:\n",
      "[[28414    10]\n",
      " [   13    44]]\n",
      "Best Model Train Time (s): 19.1080s\n",
      "Best Model Inference Time (s): 0.3840s\n",
      "Best Model CV ROC AUC Std Dev(stability): 0.0095\n",
      "\\Results with RandomUnderSampler...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      "Results with RandomUnderSampler:\n",
      "Best Parameters: {'mlp__model__optimizer': 'adam', 'mlp__model__neurons': 128, 'mlp__model__dropout_rate': 0.3, 'mlp__epochs': 50, 'mlp__batch_size': 128}\n",
      "Test Accuracy: 0.7609985604438047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86     28424\n",
      "           1       0.01      0.89      0.01        57\n",
      "\n",
      "    accuracy                           0.76     28481\n",
      "   macro avg       0.50      0.83      0.44     28481\n",
      "weighted avg       1.00      0.76      0.86     28481\n",
      "\n",
      "ROC-AUC Score: 0.9341\n",
      "Confusion Matrix for RandomUnderSampler:\n",
      "[[21623  6801]\n",
      " [    6    51]]\n",
      "Best Model Train Time (s): 1.3191s\n",
      "Best Model Inference Time (s): 0.3858s\n",
      "Best Model CV ROC AUC Std Dev(stability): 0.0208\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\ssain\\Downloads\\CCfraud\\creditcard.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Downsample the dataset for quicker training\n",
    "# Sample 50% of the data from each class to maintain balance\n",
    "df_sampled = df.groupby('Class', group_keys=False).apply(lambda x: x.sample(frac=0.5, random_state=42))\n",
    "# Train-test split (80% train, 20%test)\n",
    "\n",
    "\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df_sampled.drop(columns=['Class'])\n",
    "y = df_sampled['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to create the models\n",
    "# This builds MLP using Tensorflow/Keras\n",
    "def create_model(neurons=32, dropout_rate=0.3, optimizer='adam'):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input layer\n",
    "        tf.keras.layers.Dense(neurons, activation='relu'), # First hidden layer\n",
    "        tf.keras.layers.Dropout(dropout_rate),            # Dropout for regularization\n",
    "        tf.keras.layers.Dense(neurons // 2, activation='relu'), #2nd hidden\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  #output layer for binary classif.\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Track validation loss\n",
    "    patience=3,          # Stop after 3 epochs with no improvement\n",
    "    restore_best_weights=True  # Roll back to the best weights\n",
    ")\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "# This makes model compatible with scikit learn\n",
    "model = KerasClassifier(model=create_model, verbose=0, random_state=42,\n",
    "                       callbacks=[early_stopping],validation_split=0.2)\n",
    "\n",
    "\n",
    "# Define hyperparameter grid for RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'mlp__model__neurons': [64, 128], #neurons in first hidden\n",
    "    'mlp__model__dropout_rate': [0.3], \n",
    "    'mlp__epochs': [50],  # No. of epochs \n",
    "    'mlp__batch_size': [128],\n",
    "    'mlp__model__optimizer': ['adam']  #optimizer\n",
    "        \n",
    "}\n",
    "\n",
    "# Define stratified K-fold CrossVal\n",
    "# Ensures class dist. preserved in every fold\n",
    "stratified_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Define sampling methods\n",
    "sampling_methods = {\n",
    "    \"SMOTE\": SMOTE(),\n",
    "    \"RandomUnderSampler\": RandomUnderSampler()\n",
    "}\n",
    "\n",
    "# Loop through each sampling method\n",
    "# Loop trains and evaluates with both sampling methods\n",
    "for name, sampler in sampling_methods.items():\n",
    "    print(f\"\\Results with {name}...\")\n",
    "    \n",
    "    \n",
    "    # Create pipeline with the current sampler\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # standardize features\n",
    "        ('sampler', sampler),          # Apply sampler\n",
    "        ('mlp', model)                 # use the mlp as the model\n",
    "    ])\n",
    "    \n",
    "    # Use RandomizedSearchCV (to reduce compute/train time)\n",
    "    # RANDOMLY samples specified number of combos from hyperparameter grid\n",
    "    grid = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_grid,\n",
    "        cv=stratified_cv,\n",
    "        verbose=1,\n",
    "        n_jobs=1,\n",
    "        n_iter=2,   #number of random hyperparamater combos to try\n",
    "        scoring='roc_auc'  #optimize for roc_auc\n",
    "    )\n",
    "    \n",
    "    # Fit the RandomizedSearchCV\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test set using best model found\n",
    "    y_pred = grid_result.best_estimator_.predict(X_test) #pred class labels\n",
    "    y_prob = grid_result.best_estimator_.predict_proba(X_test)[:, 1] #pred probabs\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(f\"\\nResults with {name}:\")\n",
    "    print(f\"Best Parameters: {grid_result.best_params_}\")\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for {name}:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Access the index of the best model\n",
    "    best_index = grid.best_index_\n",
    "\n",
    "    # Extract metrics for the best model\n",
    "    best_train_time = grid.cv_results_['mean_fit_time'][best_index]  # Training time\n",
    "    best_inference_time = grid.cv_results_['mean_score_time'][best_index]  # Inference time\n",
    "    best_roc_auc_std = grid.cv_results_['std_test_score'][best_index]  # Std dev of CV ROC-AUC\n",
    "\n",
    "    # Print results for the best model\n",
    "    print(f\"Best Model Train Time (s): {best_train_time:.4f}s\")\n",
    "    print(f\"Best Model Inference Time (s): {best_inference_time:.4f}s\")\n",
    "    print(f\"Best Model CV ROC AUC Std Dev(stability): {best_roc_auc_std:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a6392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
